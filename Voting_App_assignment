

[root@ip-172-31-1-234 example-voting-app]# cd k8s-specifications/
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]# ls -rlt
total 36
-rw-r--r-- 1 root root 292 Jun 12 10:02 worker-deployment.yaml
-rw-r--r-- 1 root root 192 Jun 12 10:02 vote-service.yaml
-rw-r--r-- 1 root root 289 Jun 12 10:02 vote-deployment.yaml
-rw-r--r-- 1 root root 195 Jun 12 10:02 result-service.yaml
-rw-r--r-- 1 root root 299 Jun 12 10:02 result-deployment.yaml
-rw-r--r-- 1 root root 152 Jun 12 10:02 redis-service.yaml
-rw-r--r-- 1 root root 402 Jun 12 10:02 redis-deployment.yaml
-rw-r--r-- 1 root root 146 Jun 12 10:02 db-service.yaml
-rw-r--r-- 1 root root 401 Jun 12 10:02 db-deployment.yaml
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#


/*******************************************************************************/

[root@ip-172-31-1-234 k8s-specifications]# kubectl apply -f .
deployment.apps/db created
service/db created
deployment.apps/redis created
service/redis created
deployment.apps/result created
deployment.apps/vote created
deployment.apps/worker created
Error from server (Invalid): error when creating "result-service.yaml": Service "result" is invalid: spec.ports[0].nodePort: Invalid value: 31001: provided port is already allocated
Error from server (Invalid): error when creating "vote-service.yaml": Service "vote" is invalid: spec.ports[0].nodePort: Invalid value: 31000: provided port is already allocated
[root@ip-172-31-1-234 k8s-specifications]#


/*******************************************************************************/
[root@ip-172-31-1-234 k8s-specifications]# netstat -anp | grep 31001
tcp        0      0 0.0.0.0:31001           0.0.0.0:*               LISTEN      1363/kube-proxy
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]# netstat -anp | grep 31000
tcp        0      0 0.0.0.0:31000           0.0.0.0:*               LISTEN      1363/kube-proxy
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#

Observation: kube-proxy is listening on node port shown above.

/*******************************************************************************/

Chose new nodePort for now within the range of K8 specification defined 30000-32767.

Change voting service nodePort to:31030
Change Result service nodePort to: 31021

Recreate Result and Volting Service.

/*******************************************************************************/

[root@ip-172-31-1-234 k8s-specifications]# kubectl get svc
NAME     TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
db       ClusterIP   10.102.43.153    <none>        5432/TCP         3m10s
redis    ClusterIP   10.105.100.21    <none>        6379/TCP         3m10s
result   NodePort    10.107.204.143   <none>        5001:31021/TCP   45s
vote     NodePort    10.102.127.49    <none>        5000:31030/TCP   45s
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#


/*******************************************************************************/

Public IP: 13.214.31.25 of worker node.


[root@ip-172-31-1-234 k8s-specifications]# kubectl get Deployment
NAME     READY   UP-TO-DATE   AVAILABLE   AGE
db       1/1     1            1           12m
redis    1/1     1            1           12m
result   1/1     1            1           12m
vote     1/1     1            1           12m
worker   1/1     1            1           12m
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#


[root@ip-172-31-1-234 k8s-specifications]# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP                NODE                                               NOMINATED NODE   READINESS GATES
db-b54cd94f4-c9chb        1/1     Running   0          13m   192.168.236.165   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
redis-868d64d78-8xrnz     1/1     Running   0          13m   192.168.130.233   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
result-5d57b59f4b-rzmhn   1/1     Running   0          13m   192.168.130.234   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
vote-94849dc97-dt4q5      1/1     Running   0          13m   192.168.236.166   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
worker-dd46d7584-5f5mg    1/1     Running   0          13m   192.168.130.235   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
[root@ip-172-31-1-234 k8s-specifications]#


Observation:
1. user can cast vote and view the result to same IP:PORT.
   Launch Voting app: http://13.214.31.25:31030/
   View Result app: http://13.214.31.25:31021/

/*******************************************************************************/

Delete Voting and Worker POD: ++++++

[root@ip-172-31-1-234 k8s-specifications]# kubectl delete pod vote-94849dc97-dt4q5
pod "vote-94849dc97-dt4q5" deleted
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#


[root@ip-172-31-1-234 k8s-specifications]# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP                NODE                                               NOMINATED NODE   READINESS GATES
db-b54cd94f4-c9chb        1/1     Running   0          14m   192.168.236.165   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
redis-868d64d78-8xrnz     1/1     Running   0          14m   192.168.130.233   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
result-5d57b59f4b-rzmhn   1/1     Running   0          14m   192.168.130.234   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
vote-94849dc97-lnjd5      1/1     Running   0          15s   192.168.236.168   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
worker-dd46d7584-5f5mg    1/1     Running   0          14m   192.168.130.235   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
[root@ip-172-31-1-234 k8s-specifications]#


[root@ip-172-31-1-234 k8s-specifications]# kubectl delete pod worker-dd46d7584-5f5mg
pod "worker-dd46d7584-5f5mg" deleted


[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]#
[root@ip-172-31-1-234 k8s-specifications]# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE   IP                NODE                                               NOMINATED NODE   READINESS GATES
db-b54cd94f4-c9chb        1/1     Running   0          15m   192.168.236.165   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
redis-868d64d78-8xrnz     1/1     Running   0          15m   192.168.130.233   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
result-5d57b59f4b-rzmhn   1/1     Running   0          15m   192.168.130.234   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
vote-94849dc97-lnjd5      1/1     Running   0          73s   192.168.236.168   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
worker-dd46d7584-n5xbd    1/1     Running   0          4s    192.168.130.237   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
[root@ip-172-31-1-234 k8s-specifications]#


Observation:
1. No Impact to service after deleting voting and worker pod.
2. voting and result pods came up again since replica = 1 for both deployment.


/*******************************************************************************/

Delete DB POD: ++++++

[root@ip-172-31-1-234 k8s-specifications]# kubectl delete pod db-b54cd94f4-c9chb
pod "db-b54cd94f4-c9chb" deleted


[root@ip-172-31-1-234 k8s-specifications]# kubectl get pods -o wide
NAME                      READY   STATUS             RESTARTS   AGE     IP                NODE                                               NOMINATED NODE   READINESS GATES
db-b54cd94f4-q8x74        1/1     Running            0          45s     192.168.236.171   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
redis-868d64d78-8xrnz     1/1     Running            0          21m     192.168.130.233   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
result-5d57b59f4b-rzmhn   0/1     Error              1          21m     192.168.130.234   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
vote-94849dc97-lnjd5      1/1     Running            0          7m43s   192.168.236.168   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
worker-dd46d7584-n5xbd    0/1     CrashLoopBackOff   1          6m34s   192.168.130.237   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
[root@ip-172-31-1-234 k8s-specifications]#

[root@ip-172-31-1-234 k8s-specifications]# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE     IP                NODE                                               NOMINATED NODE   READINESS GATES
db-b54cd94f4-q8x74        1/1     Running   0          2m20s   192.168.236.171   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
redis-868d64d78-8xrnz     1/1     Running   0          23m     192.168.130.233   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
result-5d57b59f4b-rzmhn   1/1     Running   2          23m     192.168.130.234   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
vote-94849dc97-lnjd5      1/1     Running   0          9m18s   192.168.236.168   ip-172-31-10-249.ap-southeast-1.compute.internal   <none>           <none>
worker-dd46d7584-n5xbd    1/1     Running   2          8m9s    192.168.130.237   ip-172-31-1-234.ap-southeast-1.compute.internal    <none>           <none>
[root@ip-172-31-1-234 k8s-specifications]#	


Observation:
1. result-5d57b59f4b-rzmhn  POD Error for sometime.
2. worker-dd46d7584-n5xbd POD went to CrashLoopBackOff for sometime.
3. My last vote is reset because DB deployement pod is using POD volume where the scope of this volume is till the POD is running.
4. When result-5d57b59f4b-rzmhn POD is restarted, When tried to debug POD/Container has issue with DB Connectivity, It looks Container is restarted again to recover assuming Container application had issue.

	   [root@ip-172-31-1-234 ~]# kubectl logs result-5d57b59f4b-rzmhn
	Mon, 12 Jun 2023 11:23:28 GMT body-parser deprecated bodyParser: use individual json/urlencoded middlewares at server.js:73:9
	Mon, 12 Jun 2023 11:23:28 GMT body-parser deprecated undefined extended: provide extended option at ../node_modules/body-parser/index.js:104:29
	App running on port 80
	Connected to db
	Error performing query: error: relation "votes" does not exist
	Error performing query: error: relation "votes" does not exist
	Error performing query: error: relation "votes" does not exist
	node:events:491
		  throw er; // Unhandled 'error' event
		  ^

	Error: Connection terminated unexpectedly
		at Connection.<anonymous> (/node_modules/pg/lib/client.js:132:73)
		at Object.onceWrapper (node:events:627:28)
		at Connection.emit (node:events:513:28)
		at Socket.<anonymous> (/node_modules/pg/lib/connection.js:107:12)
		at Socket.emit (node:events:525:35)
		at endReadableNT (node:internal/streams/readable:1359:12)
		at process.processTicksAndRejections (node:internal/process/task_queues:82:21)
	Emitted 'error' event on Client instance at:
		at Client._handleErrorEvent (/node_modules/pg/lib/client.js:319:10)
		at Connection.<anonymous> (/node_modules/pg/lib/client.js:149:16)
		at Object.onceWrapper (node:events:627:28)
		[... lines matching original stack trace ...]
		at process.processTicksAndRejections (node:internal/process/task_queues:82:21)

	Node.js v18.12.1
	
	
[root@ip-172-31-1-234 ~]#
[root@ip-172-31-1-234 ~]#

5. My last vote is reset because DB deployement pod is using POD volume where the scope of this volume is till the POD is running.
6. Db new pod is created.
7. Both result and worker pod came to running status after few seconds.
8. I can vote again feshly and can vew result again.
9. Still user can cast vote and view the result to same IP:PORT.
   Launch Voting app: http://13.214.31.25:31030/
   View Result app: http://13.214.31.25:31021/

/*******************************************************************************/
